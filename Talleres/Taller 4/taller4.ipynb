{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Taller 4</h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Determinar y justificar si las siguientes afirmaciones son Falsas o Verdaderas.\n",
    "- La mitad de las observaciones de una muestra es menor o igual que la media.\n",
    "- La media de un conjunto de datos es el valor que ocurre con más frecuencia.\n",
    "- La media de una muestra es igual a una de las observaciones de la muestra.\n",
    "- Es preferible utilizar un instrumento de medición que genere observaciones con una desviación estándar grande.\n",
    "- Por lo general, la media y la mediana de un conjunto de datos son valores muy similares.\n",
    "\n",
    "Rta:\n",
    "- Falso, el valor que está en la mitad de las observaciones es la mediana.\n",
    "- Falso, debido a que el valor que ocurre con más frecuencia es la moda.\n",
    "- Falso, no en todos lo casos hay alguna observación igual a la media.\n",
    "- Falso, Si un intrumento da una dispersión muy grande, quiere decir que está descalibrado y no es factible.\n",
    "- Falso, pues unicamente dan los mismos valores cuando la muestra es simetrica, de resto la mediana es mayor o menor.\n",
    "\n",
    "2. Yanowitz, en In-use Emissions From Heavy-Duty Diesel Vehicles, investigó los factores que afectan las emisiones de un vehículo diesel, y obtuvo datos acerca de la emisión de partículas para una muestra de 138 vehículos conducidos en bajas altitudes (cerca del nivel del mar) y para una muestra de 62 vehículos conducidos a grandes altitudes (aproximadamente a una milla del nivel del mar). Todos los vehículos se fabricaron entre 1991 y 1996. Las muestras contenían proporciones parecidas de vehículos de bajo y alto kilometraje. Los datos, en unidades de gramos de partículas por galón de combustible consumido, se presentan en el archivo EP.txt. En esta base de datos, “emision” es la variable emisión de partículas (en unidades de gr/gal) y “altitud” es la varaible altitud a la que se conduce el vehículo (0 = baja; 1 = alta). A grandes altitudes, la presión barométrica es más baja, así la razón de eficiencia aire/combustible también es más baja. Por esta razón se pensó que la emisión de partículas podría ser mayor a grandes a altitudes.\n",
    "\n",
    "Completar la siguiente tabla:\n",
    "\n",
    "Altitud\tn\n",
    "\n",
    "Mín.\tCuar. 1\tCuar. 2\tCuar. 3\tMáx.\tMedia\tDE\tCV\n",
    "\n",
    "Baja\t138\t\t\t\t\t\t\t\t\n",
    "\n",
    "Ala\t62\n",
    "\n",
    "DE: Desviación Estándar. CV: Coeficiente de Variación.\n",
    "\n",
    "- Comparar los resultados para determinar si los datos apoyan el supuesto de que la emisión de partículas podría ser mayor a grandes a altitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      count   mean    std   min    25%   50%    75%    max     CV\n",
      "Baja  138.0  3.715  2.558  0.25  1.472  3.18  5.265  11.23  0.689\n",
      "Alta   62.0  6.596  4.519  1.11  3.488  5.75  7.755  23.38  0.685\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "RTA:\n",
    "\"\"\"\n",
    "\n",
    "# Importar el dataset\n",
    "EP = pd.read_csv('EP.txt', sep='\\t', header=0)\n",
    "# Tomar los valores con altitud baja\n",
    "baja = EP.loc[EP['altitud'] == 0]\n",
    "# Tomar los valores con altitud alta\n",
    "alta = EP.loc[EP['altitud'] == 1]\n",
    "# Calcular los tamaños de los grupos\n",
    "n_baja = len(baja)\n",
    "n_alta = len(alta)\n",
    "\n",
    "summ_baja = baja.emision.describe().to_frame().transpose()\n",
    "cv_1 = summ_baja['std'] / summ_baja['mean']\n",
    "summ_baja['CV'] = cv_1\n",
    "summ_alta = alta.emision.describe().to_frame().transpose()\n",
    "cv_2 = summ_alta['std'] / summ_alta['mean']\n",
    "summ_alta['CV'] = cv_2\n",
    "table = pd.concat([summ_baja, summ_alta], axis=0)\n",
    "table.index = ['Baja', 'Alta']\n",
    "print(table.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A altitudes más grandes la emisión de partículas es mayor en promedio, aunque en ambas muestras se tiene una variacion alta de 68%, por lo que se recomienda un análisis más profundo.\n",
    "\n",
    "3. El artículo Computing and Using Rural versus Urban Measures in Statistical Applications (C. Goodall, K. Kafadar y J. Tukey, The American Statistician, 1998:101-111) analiza los métodos para medir el grado a los cuales los condados de los Estados Unidos son urbanos más que rurales. La siguiente tabla de frecuencias presenta las frecuencias de población de los condados de los Estados Unidos.\n",
    "\n",
    "Población (en miles)\tNo. de condados\n",
    "\n",
    "0.064 – 5.405\t305\n",
    "\n",
    "5.405 – 8.780\t294\n",
    "\n",
    "8.780 – 12.417\t331\n",
    "\n",
    "12.417 – 16.384\t286\n",
    "\n",
    "16.384 – 21.619\t306\n",
    "\n",
    "21.619 – 28.526\t273\n",
    "\n",
    "28.526 – 40.342\t334\n",
    "\n",
    "40.342 – 65.536\t326\n",
    "\n",
    "65.536 – 131.072\t290\n",
    "\n",
    "131.072 – 8388.608\t323\n",
    "\n",
    "- Completar la distribución de frecuencias (frecuencia relativa y frecuencias acumuladas).\n",
    "- Calcular la media, la mediana, la moda, y el coeficiente de variación.\n",
    "- Comentar los resultados del numeral anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of frequences:\n",
      "                    Marcas de clase  No. de condados  Proporción (%)  F. Abs. Acum  F. Rel. Acum (%)\n",
      "0.064 – 5.405                 2.734              305           9.941           305             9.941\n",
      "5.405 – 8.780                 7.092              294           9.583           599            19.524\n",
      "8.780 – 12.417               10.598              331          10.789           930            30.313\n",
      "12.417 – 16.384              14.401              286           9.322          1216            39.635\n",
      "16.384 – 21.619              19.002              306           9.974          1522            49.609\n",
      "21.619 – 28.526              25.072              273           8.898          1795            58.507\n",
      "28.526 – 40.342              34.434              334          10.887          2129            69.394\n",
      "40.342 – 65.536              52.939              326          10.626          2455            80.020\n",
      "65.536 – 131.072             98.304              290           9.452          2745            89.472\n",
      "131.072 – 8388.608         4259.840              323          10.528          3068           100.000\n",
      "\n",
      "Variablility measures:\n",
      "      mean  median    mode   CV (%)\n",
      "0  474.707  21.824  38.972  273.619\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "RTA:\n",
    "\"\"\"\n",
    "\n",
    "# Get indexes\n",
    "names = np.array(['0.064 – 5.405', '5.405 – 8.780', '8.780 – 12.417', '12.417 – 16.384',\n",
    "\t '16.384 – 21.619', '21.619 – 28.526', '28.526 – 40.342', '40.342 – 65.536', '65.536 – 131.072',\n",
    "\t  '131.072 – 8388.608'])\n",
    "\n",
    "# Calculate frequencies distribution\n",
    "ni = np.array([305, 294, 331, 286, 306, 273, 334, 326, 290, 323]) # absolute frequencies\n",
    "n = sum(ni) # total number of events\n",
    "hi = ni/n # relative frequencies\n",
    "Ni = ni.cumsum() # cumulative absolute frequencies\n",
    "Hi = hi.cumsum() # cumulative relative frequencies\n",
    "li = np.array([0.064, 5.405, 8.780, 12.417, 16.384, 21.619, 28.526, 40.342, 65.536, 131.072])\n",
    "ls = np.array([5.405, 8.780, 12.417, 16.384, 21.619, 28.526, 40.342, 65.536, 131.072, 8388.608])\n",
    "yi = (li+ls)/2\n",
    "distribution = pd.DataFrame({'Marcas de clase':yi , 'No. de condados': ni, 'Proporción (%)': hi*100, 'F. Abs. Acum': Ni, 'F. Rel. Acum (%)': Hi*100})\n",
    "distribution.index = names\n",
    "print(\"Distribution of frequences:\")\n",
    "print(distribution.round(3).to_string())\n",
    "print()\n",
    "\n",
    "# Calculate the mean\n",
    "mean = sum(hi*yi)\n",
    "\n",
    "# Calculate the median\n",
    "k = np.argmin(abs(Hi-0.5))\n",
    "median = li[k]+(ls[k]-li[k])*((.5*n - Ni[k-1])/ni[k])\n",
    "\n",
    "# Calculate the mode\n",
    "k_1 = np.argmax(hi)\n",
    "mode = li[k_1]+(ls[k_1]-li[k_1])*((ni[k_1] - ni[k_1-1])/(2*ni[k_1] - ni[k_1-1] - ni[k_1+1]))\n",
    "\n",
    "# Calculate the standard deviation\n",
    "std = np.sqrt(sum(ni*(yi-mean)**2)/(n-1))\n",
    "\n",
    "# Calculate the coefficient of variation\n",
    "cv = (std/mean)*100\n",
    "\n",
    "variables = pd.DataFrame({'mean': [mean], 'median':[ median], 'mode': [mode], 'CV (%)': [cv]})\n",
    "print('Variablility measures:')\n",
    "print(variables.round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que en se tiene un alto sesgo en los datos, pues el coeficiente de variación es muy alto, es decir CV>>15%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Una muestra de temperaturas para iniciar una cierta reacción química dio un promedio muestral de (C) 87.3 y una desviación estándar muestral de (C) 1.04. ¿Cuáles son el promedio muestral y la desviación estándar en grados Fahrenheit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio Fahrenheit:\n",
      "193.14\n",
      "1.872\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "RTA:\n",
    "\"\"\"\n",
    "x_c = 87.3\n",
    "s_c = 1.04\n",
    "x_f = 36 + (x_c*(9/5))\n",
    "s_f = s_c*(9/5)\n",
    "print('Promedio Fahrenheit:')\n",
    "print(x_f)\n",
    "print(s_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Sean $X$ y $Y$ dos variables tales que:\n",
    "$$\n",
    "\\sum_{i=1}^{10}x_i=110,\\sum_{i=1}^{10}y_i=60,\\sum_{i=1}^{10}x^2_i=3156 \\ y \\ \\sum_{i=1}^{10}y^2_i=1138.\n",
    "$$\n",
    "Para cada variable calcular el coeficiente de variación. Interpretar y comparar los resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV:\n",
      "133.68% 154.96%\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "x = 110/n\n",
    "s_x = np.sqrt((3156 - n*(x**2))/(n-1))\n",
    "y = 60/n\n",
    "s_y = np.sqrt((1138 - n*(y**2))/(n-1))\n",
    "\n",
    "cv_1 = s_x/x\n",
    "cv_2 = s_y/y \n",
    "print('CV:')\n",
    "print(f'{round(cv_1*100, 2)}% {round(cv_2*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambos son altamente heterogeneos, sin embargo Y lo es mucho más"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. En cierta región la distribución de predios por extensión tiene una media de 35.4 hectáreas y una desviación típica de 19.33 hectáreas, mientras que la distribución por canon de arrendamiento tiene una media de $245,750 y una desviación de $7,470. ¿Cual de las dos distribuciones tiene mayor variabilidad? ¿Por qué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Predios:\n",
      "54.6%\n",
      "CV Arrendamiento:\n",
      "3.0%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "RTA:\n",
    "\"\"\"\n",
    "#Predios\n",
    "m_1 = 35.4\n",
    "s_1 = 19.33\n",
    "#Arrendamiento\n",
    "m_2 = 245750\n",
    "s_2 = 7470\n",
    "# Coeficientes\n",
    "cv_1 = round(s_1/m_1,3)\n",
    "cv_2 = round(s_2/m_2, 3)\n",
    "print('CV Predios:')\n",
    "print(f'{cv_1*100}%') \n",
    "print('CV Arrendamiento:')\n",
    "print(f'{cv_2*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta forma podemos ver que la distribución por predios tiene mayor variabilidad, pues calculando el coeficiente de variabilidad la cual es comparable, pues es adimensional, no da una gran diferencia respecto a la distribución por canon de arrendamiento."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
